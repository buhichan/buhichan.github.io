(window.webpackJsonp=window.webpackJsonp||[]).push([[25],{"./src/routes/fractal/shaders/ray-tracing.glsl":function(n,t,e){"use strict";e.r(t),t.default="#version 300 es\nprecision highp float;\nuniform vec2 resolution;\nin vec3 vPos;\nin vec2 vUv;\nout vec4 color;\nuniform vec2 translate;\nuniform float zoom;\nuniform vec3 params;\nuniform float time;\n// uniform mat4 modelMatrix;\n// uniform mat4 viewMatrix;\n// uniform mat4 projectionMatrix;\n\n// 使用ray tracing 来画场景. \n// 也就是对每一个像素, 追溯这一点上照到摄像头的光, 计算其从什么表面而来\n\nconst int maxIteration = 500;    \nconst float limit = 2.0;\nconst float PI = 3.1415926;\n\n#include <noise>;\n#include <fbm>;\n\n\nvec3 lightSource(vec3 normal, vec3 reflectPoint, vec3 reflectDirection, vec3 lightColor, vec3 lightPosition){\n    float diffuseFactor = .52;\n    float specularFactor = .6 + params.z / 10.0;\n    float shininess = 50.0;\n    vec3 direction = normalize( lightPosition - reflectPoint );\n    vec3 diffuse = diffuseFactor * clamp(dot(direction, normal), 0.0, 1.0) * lightColor;\n    vec3 specular = specularFactor * pow( clamp( dot(direction, reflectDirection), 0.0, 1.0), shininess) * lightColor;\n    return diffuse + specular;\n}\n\nvec3 phongModel(vec3 materialColor, vec3 normal, vec3 reflectPoint, vec3 reflectDirection){\n    // https://en.wikipedia.org/wiki/Phong_reflection_model\n    float ambientReflection = .2;\n    vec3 ambientLight = ambientReflection * materialColor;\n    return ambientLight + lightSource(\n        normal, \n        reflectPoint, \n        reflectDirection, \n        vec3(1.0,1.0,1.0), \n        vec3(.0,10.0,20.0)\n    ) + lightSource(\n        normal, \n        reflectPoint, \n        reflectDirection, \n        vec3(1.0,1.0,1.0), \n        vec3(.0,-50.0,-20.0)\n    );\n}\n\n// sphere DE\n// float distanceEstimator(vec3 point){\n//     vec3 center = vec3(0.0,0.0,0.0);\n//     float dist = length(point - center);\n//     float radius = 10.0;\n//     float theta =  atan(point.x, point.y);\n//     float phi = atan(point.z, length(point.xy));\n//     return dist - radius;\n// }\n\n// cube DE\n// float distanceEstimator(vec3 point){\n//     float radius = 5.0;\n//     // return ;\n//     vec3 dist = max(abs(point) - radius, 0.0);\n//     return length(dist);\n// }\n\n// cylinder DE\nfloat distanceEstimator(vec3 point){\n    float d1 = max(0.0, length(point.xy) - 5.0);\n    float d2 = max(0.0, abs(point.z) - 5.0);\n    return length(vec2(d1,d2));\n}\n\n\nconst int MAX_LOOP = 150;\nconst float EPSILON = 0.001;\nconst float FAR = 50.0;\nvec4 rayTracingUsingDistanceEstimator(vec3 rayOrigin, vec3 rayDirection, out vec3 reflectPoint, out vec3 reflectDirection){\n    vec3 curPoint = rayOrigin;\n    for(int i = 0; i < MAX_LOOP; i++){\n        float curDist = distanceEstimator(curPoint);\n        if(curDist < EPSILON){\n            //use gradient of distanceEstimator as normal\n            vec3 normal = normalize( vec3(\n                (distanceEstimator( curPoint + vec3(EPSILON,0.0,0.0) ) - distanceEstimator( curPoint - vec3(EPSILON,0.0,0.0) )),\n                (distanceEstimator( curPoint + vec3(0.0,EPSILON,0.0) ) - distanceEstimator( curPoint - vec3(0.0,EPSILON,0.0) )),\n                (distanceEstimator( curPoint + vec3(0.0,0.0,EPSILON) ) - distanceEstimator( curPoint - vec3(0.0,0.0,EPSILON) ))                \n            ) );\n            reflectPoint = curPoint;\n            reflectDirection = normalize(2.0 * dot(rayOrigin - reflectPoint, normal) * normal - (rayOrigin - reflectPoint));\n            vec3 materialColor = sign(normal);\n            // vec3 materialColor = vec3(0.0,0.0,0.0);\n            return vec4(\n                phongModel(\n                    materialColor,\n                    normal,\n                    reflectPoint,\n                    reflectDirection\n                ),\n                1.0\n            );\n        }else if(curDist > FAR){\n            break;\n        }else{\n            curPoint = curPoint + 0.5 * rayDirection * curDist;\n        }\n    }\n    return vec4(0.0,0.0,0.0,0.0);\n}\n\n\nvoid main(){\n    // vec2 point = ( vUv.xy + translate / resolution ) * zoom * 2.0 - 1.0;\n    vec2 point = vUv.xy * 2.0 - 1.0;\n    \n    //horizontal fov, 45deg\n\n    //假设有个球在原点, 半径为10, //有个平面在 0,0,-10, 宽度为30. 先不考虑这个平面\n    //摄像机在 50, 50, 50, 看着 -1,-1,-1,也就是看着原点\n    //                           -\n    //                       -   |\n    //                   -       |\n    //               -   |       |\n    //           -       |       |\n    // origin - )fov     |       | \n    //           -       |       |\n    //               -   |       |\n    //                   -       |\n    //                 near  -   |\n    //                   ↑       -\n    //                   ↑      far\n    //        ____________(1,1)   \n    //       |              |\n    //       |              |\n    //       |              | h\n    //       |              |\n    //     (-1,-1)----------\n    //              w\n    //      w:h = 16:9\n    //\n    //\n    //       tan(fov/2.0)\n    //       |-------/\n    //       |      /  \n    //       |     /\n    //       |    /\n    //       |   /\n    //       |  /\n    //       | /\n    //      origin\n    //\n    //\n\n    float fov = PI / 4.0;\n    float ratio = 1.0;\n    float near = 1.0;\n    float far = 100.0;\n    //相机的位置用极坐标表示.\n    //这里其实可以把相机的旋转用四元数表示\n    //matQuaternionRot [0][0] = ux*ux*oneC + cosA;\n    // matQuaternionRot [0][1] = ux*uy*oneC - uz*sinA;\n    // matQuaternionRot [0][2] = ux*uz*oneC + uy*sinA;\n    // matQuaternionRot [1][0] = uy*ux*oneC + uz*sinA;\n    // matQuaternionRot [1][1] = uy*uy*oneC + cosA;\n    // matQuaternionRot [1][2] = uy*uz*oneC - ux*sinA;\n    // matQuaternionRot [2][0] = uz*ux*oneC - uy*sinA;\n    // matQuaternionRot [2][1] = uz*uy*oneC + ux*sinA;\n    // matQuaternionRot [2][2] = uz*uz*oneC + cosA;\n\n    float theta = translate.x / 100.0;\n    float phi = translate.y / 100.0;\n\n    vec3 cameraOrigin = 50.0 * zoom * vec3(\n        cos(theta) * cos(phi),\n        sin(theta) * cos(phi),\n        sin(phi)\n    );\n    //看向原点\n    vec3 cameraDirection = normalize(-1.0 * cameraOrigin);\n    \n    vec3 cameraRight = vec3(\n        -sin(theta),\n        cos(theta),\n        0.0\n    );\n\n    vec3 cameraUp = normalize(cross(cameraRight,cameraDirection));\n\n    float tan_fov_over_2 = tan(fov/2.0);\n\n    vec3 ray = normalize(\n        cameraDirection + cameraRight * tan_fov_over_2 * point.x + cameraUp * tan_fov_over_2 * ratio * point.y\n    );\n\n    vec3 reflectPoint;\n    vec3 outRay;\n\n    color = rayTracingUsingDistanceEstimator(\n        cameraOrigin,\n        ray,\n        reflectPoint,\n        outRay\n    );\n}\n\n// vec4 crossSphere(vec3 rayOrigin, vec3 rayDirection, vec3 center, float radius, out vec3 reflectPoint, out vec3 reflectDirection){\n\n//     float b_times_cos_theta = dot( center - rayOrigin, rayDirection );\n//     //\n//     //       rayDirection  center  \n//     //             |---d--\x3e/\n//     //             |      /  \n//     // reflectPoint-     /\n//     //             |    /\n//     //             |   /\n//     //             |  /\n//     //             | /\n//     //          rayOrigin\n\n//     vec3 d = center - rayOrigin - b_times_cos_theta * rayDirection;\n\n//     float dist = length(d);\n\n//     if(dist > radius){\n//         reflectPoint = rayOrigin;\n//         reflectDirection = rayDirection;\n//         return vec4(0,0,0,0.0); //air\n//     }else{\n//         float l = sqrt(radius * radius - dist * dist);\n//         vec3 normal = - normalize(d + rayDirection * l);\n//         reflectPoint = center + radius * normal;\n//         reflectDirection = normalize(2.0 * dot(rayOrigin - reflectPoint, normal) * normal - (rayOrigin - reflectPoint));\n//         vec3 materialColor = sign(normal);\n//         return vec4(phongModel(materialColor, normal, reflectPoint, reflectDirection), 1.0);\n//     }\n// }"}}]);
//# sourceMappingURL=25.a322e4ba9c5fc7924ac4.js.map